{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ion()\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from models.transformer import Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'cuda'"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.set_default_tensor_type(torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor)\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "learning_rate = 1e-3\n",
    "batch_size = 32\n",
    "max_sequence_length = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and pre process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/eng_french.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "  English words/sentences French words/sentences\n0                     Hi.                 Salut!\n1                    Run!                Cours !\n2                    Run!               Courez !\n3                    Who?                  Qui ?\n4                    Wow!             Ça alors !",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>English words/sentences</th>\n      <th>French words/sentences</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Hi.</td>\n      <td>Salut!</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Run!</td>\n      <td>Cours !</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Run!</td>\n      <td>Courez !</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Who?</td>\n      <td>Qui ?</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Wow!</td>\n      <td>Ça alors !</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2Index:\n",
    "    def __init__(self, language, sentences):\n",
    "        self.language = language\n",
    "\n",
    "        self.map = dict()\n",
    "        self.reverse_map = list()\n",
    "\n",
    "        self.add_word('<padding>')\n",
    "        self.add_word('<unk>')\n",
    "\n",
    "        for sent in sentences:\n",
    "            for word in sent:\n",
    "                self.add_word(word)\n",
    "\n",
    "    def add_word(self, word):\n",
    "        if word not in self.map:\n",
    "            self.map[word] = len(self.map)\n",
    "            self.reverse_map.append(word)\n",
    "\n",
    "    def get_index(self, word):\n",
    "        if word in self.map:\n",
    "            return self.map[word]\n",
    "        \n",
    "        return self.map['<unk>']\n",
    "\n",
    "    def indexify_sentence(self, sentence):\n",
    "        return [self.get_index(word) for word in sentence]\n",
    "\n",
    "    def get_word(self, index):\n",
    "        if index < len(self.map):\n",
    "            return self.reverse_map[index]\n",
    "        \n",
    "        return '<unk>'\n",
    "\n",
    "    def sentencify_indices(self, indices):\n",
    "        return [self.get_word(index) for index in indices]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__}\\n\\tLanguage: {self.language}\\n\\tWords: {len(self.map)}'\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, data, src_language, tgt_language, max_length=16):\n",
    "        self.max_length = max_length\n",
    "        src_sentences, src_prune_indices = self.tokenize(data, 0)\n",
    "        tgt_sentences, tgt_prune_indices = self.tokenize(data, 1)\n",
    "\n",
    "        prune_indices = src_prune_indices.union(tgt_prune_indices)\n",
    "\n",
    "        self.src_word2index, self.src_tokens = self.indexify(src_language, src_sentences, prune_indices)\n",
    "        self.tgt_word2index, self.tgt_tokens = self.indexify(tgt_language, tgt_sentences, prune_indices)\n",
    "\n",
    "    def pad(self, A):\n",
    "        arr = np.zeros(self.max_length)\n",
    "        arr[:len(A)] = A\n",
    "        return arr\n",
    "\n",
    "    def tokenize(self, data, index):\n",
    "        sentences = data.iloc[:, index]\n",
    "        sentences = sentences.apply(word_tokenize)\n",
    "\n",
    "        prune_indices = sentences[sentences.map(len) > self.max_length].index\n",
    "\n",
    "        return sentences, prune_indices\n",
    "\n",
    "    def indexify(self, language, sentences, prune_indices):\n",
    "        sentences = sentences.drop(prune_indices)\n",
    "        word2index = Word2Index(language, sentences)\n",
    "        sentences = sentences.apply(word2index.indexify_sentence)\n",
    "        sentences = sentences.apply(self.pad)\n",
    "\n",
    "        return word2index, sentences\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.src_tokens)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        return torch.LongTensor(self.src_tokens.iloc[idx]), torch.LongTensor(self.tgt_tokens.iloc[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TranslationDataset(data, \"english\", \"french\", max_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = random_split(dataset, [math.floor(0.8 * len(dataset)), math.ceil(0.2 * len(dataset))])\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab_length = len(dataset.src_word2index)\n",
    "tgt_vocab_length = len(dataset.tgt_word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(\n",
    "    src_vocab_length, \n",
    "    tgt_vocab_length,\n",
    "    max_sequence_length\n",
    ").to(device)\n",
    "\n",
    "criterion = CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), learning_rate, betas=[0.9, 0.98], eps=10e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('saved/best.h5', map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "19"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "checkpoint['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = max_sequence_length\n",
    "np_mask = torch.triu(torch.ones(size, size))\n",
    "np_mask = np_mask.float().masked_fill(np_mask == 1, float(-1e8)).masked_fill(np_mask == 0, float(0.0))\n",
    "np_mask = np_mask.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Epoch: 1 Average Train Batch Loss: 0.12789324078822636: 100%|██████████| 4323/4323 [17:14<00:00,  4.18it/s]\nEpoch: 1 Average Val Batch Loss: 0.1205718625099101: 100%|██████████| 1081/1081 [01:15<00:00, 14.38it/s]\nEpoch: 2 Average Train Batch Loss: 0.13030676945368366: 100%|██████████| 4323/4323 [15:45<00:00,  4.57it/s]\nEpoch: 2 Average Val Batch Loss: 0.12828866199734143: 100%|██████████| 1081/1081 [01:42<00:00, 10.53it/s]\nEpoch: 3 Average Train Batch Loss: 0.1302434488732344:  91%|█████████ | 3925/4323 [14:00<01:25,  4.67it/s]\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-46d0167815b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/ml/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/ml/transformer/models/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, tgt, mask)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m# Decoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mtgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer_decoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;31m# Linear Transformation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/ml/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/ml/transformer/models/components.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tgt, encoded_src, mask)\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded_src\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             \u001b[0mtgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded_src\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/ml/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/ml/transformer/models/components.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tgt, encoded_src, mask)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# Multihead Attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mtgt2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_head_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded_src\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded_src\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;31m# Dropout 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/ml/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/ml/transformer/models/attention.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, Q, K, V, mask)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;31m# Attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         heads = torch.cat(\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0;34m[\u001b[0m\u001b[0mscaled_dot_product_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m             \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         )\n",
      "\u001b[0;32m~/dev/ml/transformer/models/attention.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;31m# Attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         heads = torch.cat(\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0;34m[\u001b[0m\u001b[0mscaled_dot_product_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m             \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         )\n",
      "\u001b[0;32m~/dev/ml/transformer/models/attention.py\u001b[0m in \u001b[0;36mscaled_dot_product_attention\u001b[0;34m(Q, K, V, Dk, mask)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mdot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdot\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mMultiHeadAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_epoch_losses = []\n",
    "val_epoch_losses = []\n",
    "train_batch_losses = []\n",
    "val_batch_losses = []\n",
    "best_loss = 1e8\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    train_epoch_loss = 0\n",
    "    model.train()\n",
    "    pbar = tqdm(train_dataloader)\n",
    "    for i, batch in enumerate(pbar):\n",
    "        src, tgt = batch[0].to(device), batch[1].to(device)\n",
    "\n",
    "        out = model(src, tgt, np_mask)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss = criterion(\n",
    "            out.view(out.shape[0] * max_sequence_length, tgt_vocab_length),\n",
    "            tgt.view(tgt.shape[0] * max_sequence_length)\n",
    "        )\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        train_epoch_loss += loss.item()\n",
    "        train_batch_losses.append(loss.item())\n",
    "        pbar.set_description(\"Epoch: {} Average Train Batch Loss: {}\".format(epoch + 1, train_epoch_loss / (i + 1)))\n",
    "\n",
    "    val_epoch_loss = 0\n",
    "    model.eval()\n",
    "    pbar = tqdm(test_dataloader)\n",
    "    for i, batch in enumerate(pbar):\n",
    "        src, tgt = batch[0].to(device), batch[1].to(device)\n",
    "\n",
    "        out = model(src, tgt, np_mask)\n",
    "\n",
    "        loss = criterion(\n",
    "            out.view(out.shape[0] * max_sequence_length, tgt_vocab_length),\n",
    "            tgt.view(tgt.shape[0] * max_sequence_length)\n",
    "        )\n",
    "        val_epoch_loss += loss.item()\n",
    "        val_batch_losses.append(loss.item())\n",
    "        pbar.set_description(\"Epoch: {} Average Val Batch Loss: {}\".format(epoch + 1, val_epoch_loss / (i + 1)))\n",
    "\n",
    "    train_epoch_losses.append(train_epoch_loss)\n",
    "    val_epoch_losses.append(val_epoch_loss)\n",
    "\n",
    "    if val_epoch_loss < best_loss:\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'train_loss': train_epoch_loss,\n",
    "            'val_loss': val_epoch_loss,\n",
    "        }, 'saved/best.h5')\n",
    "        best_loss = val_epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[<matplotlib.lines.Line2D at 0x7f0347d31160>]"
     },
     "metadata": {},
     "execution_count": 22
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"249.140954pt\" version=\"1.1\" viewBox=\"0 0 381.65 249.140954\" width=\"381.65pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-05-21T22:34:34.023000</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.1, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M -0 249.140954 \nL 381.65 249.140954 \nL 381.65 0 \nL -0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 39.65 225.262829 \nL 374.45 225.262829 \nL 374.45 7.822829 \nL 39.65 7.822829 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"md5f1549e87\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"54.868182\" xlink:href=\"#md5f1549e87\" y=\"225.262829\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0.0 -->\n      <g transform=\"translate(46.916619 239.861267)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n        <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"94.916029\" xlink:href=\"#md5f1549e87\" y=\"225.262829\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 2.5 -->\n      <g transform=\"translate(86.964466 239.861267)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n        <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"134.963876\" xlink:href=\"#md5f1549e87\" y=\"225.262829\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 5.0 -->\n      <g transform=\"translate(127.012313 239.861267)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"175.011722\" xlink:href=\"#md5f1549e87\" y=\"225.262829\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 7.5 -->\n      <g transform=\"translate(167.06016 239.861267)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 8.203125 72.90625 \nL 55.078125 72.90625 \nL 55.078125 68.703125 \nL 28.609375 0 \nL 18.3125 0 \nL 43.21875 64.59375 \nL 8.203125 64.59375 \nz\n\" id=\"DejaVuSans-55\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"215.059569\" xlink:href=\"#md5f1549e87\" y=\"225.262829\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 10.0 -->\n      <g transform=\"translate(203.926757 239.861267)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"255.107416\" xlink:href=\"#md5f1549e87\" y=\"225.262829\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 12.5 -->\n      <g transform=\"translate(243.974604 239.861267)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"295.155263\" xlink:href=\"#md5f1549e87\" y=\"225.262829\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 15.0 -->\n      <g transform=\"translate(284.022451 239.861267)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"335.20311\" xlink:href=\"#md5f1549e87\" y=\"225.262829\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 17.5 -->\n      <g transform=\"translate(324.070298 239.861267)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_9\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m3f285824cd\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#m3f285824cd\" y=\"210.607699\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 200 -->\n      <g transform=\"translate(13.5625 214.406918)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#m3f285824cd\" y=\"185.656639\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 400 -->\n      <g transform=\"translate(13.5625 189.455858)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#m3f285824cd\" y=\"160.705579\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 600 -->\n      <g transform=\"translate(13.5625 164.504798)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#m3f285824cd\" y=\"135.754519\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 800 -->\n      <g transform=\"translate(13.5625 139.553738)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-56\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#m3f285824cd\" y=\"110.803459\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 1000 -->\n      <g transform=\"translate(7.2 114.602678)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#m3f285824cd\" y=\"85.852399\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 1200 -->\n      <g transform=\"translate(7.2 89.651618)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_15\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#m3f285824cd\" y=\"60.901339\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 1400 -->\n      <g transform=\"translate(7.2 64.700558)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_16\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#m3f285824cd\" y=\"35.950279\"/>\n      </g>\n     </g>\n     <g id=\"text_16\">\n      <!-- 1600 -->\n      <g transform=\"translate(7.2 39.749498)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_9\">\n     <g id=\"line2d_17\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#m3f285824cd\" y=\"10.999219\"/>\n      </g>\n     </g>\n     <g id=\"text_17\">\n      <!-- 1800 -->\n      <g transform=\"translate(7.2 14.798437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-56\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_18\">\n    <path clip-path=\"url(#p13cdf077b7)\" d=\"M 54.868182 17.706466 \nL 70.887321 52.544384 \nL 86.906459 76.226508 \nL 102.925598 93.753322 \nL 118.944737 107.348094 \nL 134.963876 118.881651 \nL 150.983014 129.358922 \nL 167.002153 139.019445 \nL 183.021292 147.572696 \nL 199.040431 154.73996 \nL 215.059569 160.423385 \nL 231.078708 164.81377 \nL 247.097847 168.310942 \nL 263.116986 171.256894 \nL 279.136124 173.796801 \nL 295.155263 175.998034 \nL 311.174402 177.890581 \nL 327.193541 179.313084 \nL 343.212679 180.388745 \nL 359.231818 181.212343 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_19\">\n    <path clip-path=\"url(#p13cdf077b7)\" d=\"M 54.868182 187.243556 \nL 70.887321 192.925605 \nL 86.906459 197.151985 \nL 102.925598 200.471234 \nL 118.944737 203.049135 \nL 134.963876 205.116478 \nL 150.983014 206.790406 \nL 167.002153 208.275619 \nL 183.021292 209.580553 \nL 199.040431 210.684246 \nL 215.059569 211.609872 \nL 231.078708 212.321617 \nL 247.097847 212.992394 \nL 263.116986 213.490478 \nL 279.136124 213.997887 \nL 295.155263 214.365773 \nL 311.174402 214.601798 \nL 327.193541 214.93675 \nL 343.212679 215.096816 \nL 359.231818 215.379193 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 39.65 225.262829 \nL 39.65 7.822829 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 374.45 225.262829 \nL 374.45 7.822829 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 39.65 225.262829 \nL 374.45 225.262829 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 39.65 7.822829 \nL 374.45 7.822829 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p13cdf077b7\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"39.65\" y=\"7.822829\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "plt.plot([i for i in range(len(train_epoch_losses))], train_epoch_losses)\n",
    "plt.plot([i for i in range(len(val_epoch_losses))], val_epoch_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sentence):\n",
    "    model.eval()\n",
    "    sentence = word_tokenize(sentence)\n",
    "    sentence = dataset.src_word2index.indexify_sentence(sentence)\n",
    "    sentence = torch.LongTensor(dataset.pad(sentence)).unsqueeze(0).to(device)\n",
    "    tgt = torch.zeros((1, max_sequence_length), dtype=torch.long)\n",
    "\n",
    "    for i in range(max_sequence_length):\n",
    "        out = model.forward(sentence, tgt, np_mask)\n",
    "\n",
    "        out = F.softmax(out.squeeze()).detach().cpu().numpy()\n",
    "        a = [i for i in range(len(out[i]))]\n",
    "        tgt[0][i] = np.random.choice(a, p=out[i])\n",
    "\n",
    "    print(dataset.tgt_word2index.sentencify_indices(tgt.squeeze().tolist()))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bitmlvenv9529b9fd541d4d7697c1599668c07e5d",
   "display_name": "Python 3.8.2 64-bit ('ml': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}